{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a36e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2508a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '../data'\n",
    "\n",
    "df_air_env = pd.read_csv(prefix + '/air_quality_env_processed.csv')\n",
    "df_humidity = pd.read_csv(prefix + '/averaged_humidity.csv')\n",
    "df_temperature = pd.read_csv(prefix + '/averaged_temperature.csv')\n",
    "df_pressure = pd.read_csv(prefix + '/andy/pressure.csv')\n",
    "df_wind = pd.read_csv(prefix + '/andy/wind.csv')\n",
    "\n",
    "df_air_env = df_air_env.rename(columns={\"report_datetime\": \"datetime\"})\n",
    "df_humidity = df_humidity.rename(columns={\"Hour\": \"datetime\", \"Station\": \"station\", \"Relative Humidity(percent)\": \"humidity\"})\n",
    "df_temperature = df_temperature.rename(columns={\"Hour\": \"datetime\", \"Station\": \"station\", \"Average Max Temp\": \"max_temp\", \"Average Min Temp\": \"min_temp\"})\n",
    "df_pressure = df_pressure.rename(columns={\"Automatic Weather Station\": \"station\", \"Mean Sea Level Pressure(hPa)\": \"pressure\", \"Datetime\": \"datetime\"})\n",
    "df_wind = df_wind.rename(columns={\"Automatic Weather Station\": \"station\", \"10-Minute Mean Wind Direction(Compass points)\": \"wind_direction\", \"10-Minute Mean Speed(km/hour)\": \"wind_speed\", \"10-Minute Maximum Gust(km/hour)\": \"max_wind_speed\", \"Datetime\": \"datetime\"})\n",
    "\n",
    "df_air_env = df_air_env.drop(columns=['Unnamed: 0'])\n",
    "df_pressure = df_pressure.drop(columns=['Date time'])\n",
    "\n",
    "df_air_env['datetime'] = pd.to_datetime(df_air_env['datetime'])\n",
    "df_humidity['datetime'] = pd.to_datetime(df_humidity['datetime'])\n",
    "df_pressure['datetime'] = pd.to_datetime(df_pressure['datetime'])\n",
    "df_temperature['datetime'] = pd.to_datetime(df_temperature['datetime'])\n",
    "df_wind['datetime'] = pd.to_datetime(df_wind['datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14ac98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearing = {\n",
    "    \"North\": 0,\n",
    "    \"Northeast\": 45,\n",
    "    \"East\": 90,\n",
    "    \"Southeast\": 135,\n",
    "    \"South\": 180,\n",
    "    \"Southwest\": 225,\n",
    "    \"West\": 270,\n",
    "    \"Northwest\": 315,\n",
    "}\n",
    "\n",
    "def format_wind_direction(wind_direction):\n",
    "    if type(wind_direction) == float:\n",
    "        wind_direction = None\n",
    "    elif '[' in wind_direction:\n",
    "        wind_direction = set(ast.literal_eval(wind_direction.replace(' ', ','))) - set(['Calm', 'Variable', 'nan'])\n",
    "    else:\n",
    "        wind_direction = set([wind_direction]) - set(['Calm', 'Variable', 'nan'])\n",
    "    \n",
    "    if wind_direction == set():\n",
    "        cardinal = -10\n",
    "    elif wind_direction is None:\n",
    "        cardinal = None\n",
    "    else:\n",
    "        cardinal = sum([bearing[d] for d in wind_direction])\n",
    "        \n",
    "    return cardinal\n",
    "\n",
    "df_wind['wind_direction'] = df_wind['wind_direction'].apply(format_wind_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cfd2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hong Kong SAR official bounds:\n",
    "lat_min, lat_max = 22 + 9/60 + 14/3600, 22 + 33/60 + 44/3600    # 22.1333… to 22.5833…\n",
    "lon_min, lon_max = 113 + 50/60 + 7/3600, 114 + 26/60 + 30/3600  # 113.8167… to 114.5167…\n",
    "\n",
    "# then build your bins as before:\n",
    "grid_size = 0.009  # ~1km in degrees\n",
    "# grid_size = 0.1\n",
    "\n",
    "lat_bins = np.arange(lat_min, lat_max + grid_size, grid_size)\n",
    "lon_bins = np.arange(lon_min, lon_max + grid_size, grid_size)\n",
    "lat_centers = lat_bins[:-1] + grid_size/2\n",
    "lon_centers = lon_bins[:-1] + grid_size/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30c4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epd_stations = pd.read_csv(prefix + '/stations_epd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c8f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hko_stations = pd.read_csv(prefix + '/stations_hko.csv')\n",
    "df_hko_stations[\"station_code\"] = df_hko_stations[\"station_code\"].str.replace(r\"[\\(\\)]\", \"\", regex=True)\n",
    "\n",
    "dms_re = re.compile(r\"\"\"^\\s*      # optional leading space\n",
    "                        (\\d+)[°o] # degrees + deg‐symbol (degree sign or \"o\")\n",
    "                        (\\d+)'    # minutes + apostrophe\n",
    "                        (\\d+)\"    # seconds + double‐quote\n",
    "                     \"\"\", re.VERBOSE)\n",
    "\n",
    "def dms_to_decimal(dms_str):\n",
    "    m = dms_re.match(dms_str)\n",
    "    if not m:\n",
    "        return pd.NA\n",
    "    deg, mins, secs = map(float, m.groups())\n",
    "    return deg + mins/60 + secs/3600\n",
    "\n",
    "df_hko_stations[\"Latitude\"]  = df_hko_stations[\"Latitude\"].apply(dms_to_decimal)\n",
    "df_hko_stations[\"Longitude\"] = df_hko_stations[\"Longitude\"].apply(dms_to_decimal)\n",
    "df_hko_stations = df_hko_stations.drop(columns=['Elevation of ground above mean sea-level (metres)', 'Wind', 'Temp', 'Relative Humidity', 'Pressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a5ef400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cell(lat, lon, lat_bins, lon_bins):\n",
    "    i = np.digitize(lat,  lat_bins) - 1\n",
    "    j = np.digitize(lon,  lon_bins) - 1\n",
    "    if not (0 <= i < len(lat_bins)-1 and 0 <= j < len(lon_bins)-1):\n",
    "        return pd.Series({'lat_idx':np.nan,'lon_idx':np.nan})\n",
    "    return pd.Series({'lat_idx':i,'lon_idx':j})\n",
    "\n",
    "# apply to each station\n",
    "df_epd_stations[['lat_idx','lon_idx']] = df_epd_stations.apply(\n",
    "    lambda row: find_cell(row['Latitude'], row['Longitude'], lat_bins, lon_bins),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_hko_stations[['lat_idx','lon_idx']] = df_hko_stations.apply(\n",
    "    lambda row: find_cell(row['Latitude'], row['Longitude'], lat_bins, lon_bins),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15770a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) define the global hour\\ly index\n",
    "full_time_index = pd.date_range(\n",
    "    start=\"2024-01-01 00:00\",\n",
    "    end  =\"2024-12-31 23:00\",\n",
    "    freq ='1H'\n",
    ")\n",
    "\n",
    "def temporal_interpolate_fixed(\n",
    "    df: pd.DataFrame,\n",
    "    station_col: str,\n",
    "    time_col: str,\n",
    "    value_cols: list[str],\n",
    "    full_idx: pd.DatetimeIndex = full_time_index\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Ensures time_col is datetime\n",
    "    2) For each station:\n",
    "       • reindex to full_idx (same for all)\n",
    "       • interpolate(value_cols) along time\n",
    "       • reattach station label to every row\n",
    "    Returns: one row per station per hour in full_idx\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "\n",
    "    out = []\n",
    "    for stn, grp in df.groupby(station_col, sort=False):\n",
    "        # set & sort on timestamp\n",
    "        grp = grp.set_index(time_col).sort_index()\n",
    "\n",
    "        # reindex to the global index\n",
    "        grp = grp.reindex(full_idx)\n",
    "\n",
    "        # interpolate your numeric columns in time\n",
    "        grp[value_cols] = (\n",
    "            grp[value_cols]\n",
    "              .interpolate(method='time', limit_direction='both')\n",
    "        )\n",
    "\n",
    "        # put the station name back on every row\n",
    "        grp[station_col] = stn\n",
    "\n",
    "        out.append(grp)\n",
    "\n",
    "    # concatenate, reset index to bring time_col back as a column\n",
    "    result = (\n",
    "        pd.concat(out, axis=0)\n",
    "          .reset_index()\n",
    "          .rename(columns={'index': time_col})\n",
    "    )\n",
    "    return result\n",
    "\n",
    "# --- Apply to your five dataframes ---\n",
    "\n",
    "df_air_env = temporal_interpolate_fixed(\n",
    "    df_air_env,\n",
    "    station_col='station',\n",
    "    time_col='datetime',\n",
    "    value_cols=['so2','no','no2','rsp','o3','fsp']\n",
    ")\n",
    "\n",
    "df_humidity = temporal_interpolate_fixed(\n",
    "    df_humidity,\n",
    "    station_col='station',\n",
    "    time_col='datetime',\n",
    "    value_cols=['humidity']\n",
    ")\n",
    "\n",
    "df_temperature = temporal_interpolate_fixed(\n",
    "    df_temperature,\n",
    "    station_col='station',\n",
    "    time_col='datetime',\n",
    "    value_cols=['max_temp','min_temp']\n",
    ")\n",
    "\n",
    "df_pressure = temporal_interpolate_fixed(\n",
    "    df_pressure,\n",
    "    station_col='station',\n",
    "    time_col='datetime',\n",
    "    value_cols=['pressure']\n",
    ")\n",
    "\n",
    "df_wind = temporal_interpolate_fixed(\n",
    "    df_wind,\n",
    "    station_col='station',\n",
    "    time_col='datetime',\n",
    "    value_cols=['wind_speed','max_wind_speed', 'wind_direction']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f074aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_map_humidity = {\n",
    "    'HK Observatory': 'Hong Kong Observatory',\n",
    "    'HK Park': 'Hong Kong Park',\n",
    "    'Chek Lap Kok': 'Hong Kong International Airport',\n",
    "    'Tsing Yi': 'New Tsing Yi Station',\n",
    "    'Pak Tam Chung': 'Pak Tam Chung (Tsak Yue Wu)',\n",
    "    'Tai Po': 'Tai Po(Yuen Chau Tsai Park)',\n",
    "    'Tuen Mun': 'Tuen Mun Children and Juvenile Home',\n",
    "    }\n",
    "manual_map_temperature = {\n",
    "    'HK Observatory': 'Hong Kong Observatory',\n",
    "    'HK Park': 'Hong Kong Park',\n",
    "    'Chek Lap Kok': 'Hong Kong International Airport',\n",
    "    'Tsing Yi': 'New Tsing Yi Station',\n",
    "    'Pak Tam Chung': 'Pak Tam Chung (Tsak Yue Wu)',\n",
    "    'Tai Po': 'Tai Po(Yuen Chau Tsai Park)',\n",
    "    'Tuen Mun': 'Tuen Mun Children and Juvenile Home',\n",
    "    'Tsuen Wan Ho Koon': 'Tsuen Wan'\n",
    "}\n",
    "manual_map_pressure = {\n",
    "    'HK Observatory': 'Hong Kong Observatory',\n",
    "    'Chek Lap Kok': 'Hong Kong International Airport',\n",
    "    'Tai Po': 'Tai Po(Yuen Chau Tsai Park)'\n",
    "}\n",
    "manual_map_wind = {\n",
    "    'Tsing Yi': 'Tsing Yi Wind Station',\n",
    "    'Tuen Mun': 'Tuen Mun Government Offices',\n",
    "    'Star Ferry': 'Star Ferry(Kowloon)',\n",
    "    'Chek Lap Kok': 'Hong Kong International Airport',\n",
    "    }\n",
    "others = [df_humidity, df_temperature, df_pressure, df_wind]\n",
    "for df, mapping in zip(others, [manual_map_humidity,manual_map_temperature,manual_map_pressure,manual_map_wind]):\n",
    "  df[\"station\"] = (\n",
    "      df[\"station\"]\n",
    "        .map(mapping)                  \n",
    "        .fillna(df[\"station\"])           \n",
    "  )\n",
    "\n",
    "df_humidity = pd.merge(df_humidity, df_hko_stations, 'left', left_on='station', right_on='station')\n",
    "df_temperature = pd.merge(df_temperature, df_hko_stations, 'left', left_on='station', right_on='station')\n",
    "df_pressure = pd.merge(df_pressure, df_hko_stations, 'left', left_on='station', right_on='station')\n",
    "df_wind = pd.merge(df_wind, df_hko_stations, 'left', left_on='station', right_on='station')\n",
    "df_air_env = pd.merge(df_air_env, df_epd_stations, 'left', left_on='station', right_on='station')\n",
    "\n",
    "df_humidity = df_humidity.drop(columns=['station', 'Latitude', 'Longitude', 'station_code'])\n",
    "df_temperature = df_temperature.drop(columns=['station', 'Latitude', 'Longitude', 'station_code'])\n",
    "df_pressure = df_pressure.drop(columns=['station', 'Latitude', 'Longitude', 'station_code'])\n",
    "df_wind = df_wind.drop(columns=['station', 'Latitude', 'Longitude', 'station_code'])\n",
    "df_air_env = df_air_env.drop(columns=['station', 'Latitude', 'Longitude', 'station_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f78eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    df_air_env,\n",
    "    df_humidity,\n",
    "    df_temperature,\n",
    "    df_pressure,\n",
    "    df_wind\n",
    "]\n",
    "\n",
    "# Perform outer join using reduce and merge\n",
    "df_all = reduce(lambda left, right: pd.merge(left, right, on=['datetime','lat_idx','lon_idx'], how='outer'), dfs)\n",
    "month_to_season = {12:0,1:0,2:0, 3:1,4:1,5:1, 6:2,7:2,8:2, 9:3,10:3,11:3}\n",
    "df_all['season'] = df_all['datetime'].dt.month.map(month_to_season)\n",
    "df_all['is_weekend'] = df_all['datetime'].dt.dayofweek.isin([5,6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2873f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['so2', 'no', 'no2', 'rsp', 'o3', 'fsp', 'humidity', 'max_temp', 'min_temp', 'pressure', 'wind_direction', 'wind_speed', 'max_wind_speed', 'season', 'is_weekend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11213565",
   "metadata": {},
   "outputs": [],
   "source": [
    "times    = pd.date_range(\"2024-01-01 00:00\", \"2024-12-31 23:00\", freq=\"1H\")\n",
    "H        = len(lat_centers)\n",
    "W        = len(lon_centers)\n",
    "lat_idxs = np.arange(H)\n",
    "lon_idxs = np.arange(W)\n",
    "\n",
    "full_idx = pd.MultiIndex.from_product(\n",
    "    [times, lat_idxs, lon_idxs],\n",
    "    names=[\"datetime\",\"lat_idx\",\"lon_idx\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a38ce4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'so2', 'no', 'no2', 'rsp', 'o3', 'fsp', 'lat_idx',\n",
       "       'lon_idx', 'humidity', 'max_temp', 'min_temp', 'pressure',\n",
       "       'wind_direction', 'wind_speed', 'max_wind_speed', 'season',\n",
       "       'is_weekend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bcb5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df_all.set_index([\"datetime\",\"lat_idx\",\"lon_idx\"]).to_xarray()\n",
    "\n",
    "ds = ds.reindex(\n",
    "    datetime=times,\n",
    "    lat_idx=lat_idxs,\n",
    "    lon_idx=lon_idxs\n",
    ")\n",
    "\n",
    "images = ds.to_array().transpose(\"datetime\",\"variable\",\"lat_idx\",\"lon_idx\").values\n",
    "images_filled = images.copy()\n",
    "T, C, H, W = images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2c2c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8784/8784 [03:52<00:00, 37.72it/s]\n"
     ]
    }
   ],
   "source": [
    "def fill2d_griddata(arr2d, method='cubic'):\n",
    "    X, Y = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')\n",
    "\n",
    "    # known points\n",
    "    mask = ~np.isnan(arr2d)\n",
    "    pts = np.argwhere(mask)\n",
    "    vals = arr2d[mask]\n",
    "\n",
    "    # interpolate onto full grid\n",
    "    # 1) cubic inside hull\n",
    "    out_cubic = griddata(pts, vals, (X, Y), method='cubic')\n",
    "\n",
    "    # 2) nearest everywhere\n",
    "    out_nearest = griddata(pts, vals, (X, Y), method='nearest')\n",
    "\n",
    "    # 3) fill holes\n",
    "    filled = np.where(np.isnan(out_cubic), out_nearest, out_cubic)\n",
    "    \n",
    "    return filled\n",
    "\n",
    "# usage\n",
    "for t in tqdm(range(T)):\n",
    "    for c in range(C):\n",
    "        arr = images_filled[t, c]\n",
    "        if np.isnan(arr).any():\n",
    "            images_filled[t, c] = fill2d_griddata(arr, method='linear')\n",
    "\n",
    "np.save(prefix + '/images_filled_griddata.npy', images_filled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hku_fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
